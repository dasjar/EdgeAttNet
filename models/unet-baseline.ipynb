{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ENJOO1SoM0B6",
   "metadata": {
    "id": "ENJOO1SoM0B6"
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546fd89-2db1-4245-bb1c-890004cf8066",
   "metadata": {
    "id": "c546fd89-2db1-4245-bb1c-890004cf8066"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "from pycocotools import mask as mask_utils\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.polynomial.polynomial import polyvander2d, polyval2d\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import binary_opening, rectangle, remove_small_objects\n",
    "from skimage.measure import label, regionprops\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MXNR1DsKhFQa",
   "metadata": {
    "id": "MXNR1DsKhFQa"
   },
   "source": [
    "preparing data loaders using pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ItTWw1TMhRI2",
   "metadata": {
    "id": "ItTWw1TMhRI2"
   },
   "outputs": [],
   "source": [
    "def extract_year_from_image_id(image_id):\n",
    "    try:\n",
    "        return int(image_id.split('-')[1][:4])\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to extract year from image ID '{image_id}': {e}\")\n",
    "\n",
    "def split_dataset_by_year(dataset, train_years, val_years, test_years):\n",
    "    train_indices, val_indices, test_indices = [], [], []\n",
    "    for idx, image_id in enumerate(dataset.image_ids):\n",
    "        year = extract_year_from_image_id(image_id)\n",
    "        if year in train_years:\n",
    "            train_indices.append(idx)\n",
    "        elif year in val_years:\n",
    "            val_indices.append(idx)\n",
    "        elif year in test_years:\n",
    "            test_indices.append(idx)\n",
    "    return train_indices, val_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8MA_20XPmdE-",
   "metadata": {
    "id": "8MA_20XPmdE-"
   },
   "outputs": [],
   "source": [
    "# Image + Mask Transform Wrapper ---\n",
    "class ImageMaskTransform:\n",
    "    def __init__(self, image_size=(512, 512)):\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]) \n",
    "        ])\n",
    "        # Mask is NOT resized to avoid blurring, just converted to tensor\n",
    "        self.mask_transform = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        image = self.image_transform(image)\n",
    "        mask = self.mask_transform(mask)\n",
    "        return image, mask\n",
    "\n",
    "# Custom Dataset\n",
    "class FilamentDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_index = self.index_images_by_id(image_dir)\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_ids = sorted(self.image_index.keys())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_path = self.image_index[image_id]\n",
    "        mask_path = os.path.join(self.mask_dir, f\"{image_id}.png\")\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "        mask = (mask > 0).float()  # binarize mask\n",
    "        return image, mask, image_id\n",
    "\n",
    "    @staticmethod\n",
    "    def index_images_by_id(image_dir, extensions=(\".jpg\", \".jpeg\", \".png\")):\n",
    "        image_index = {}\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(extensions):\n",
    "                    image_id = os.path.splitext(file)[0]\n",
    "                    image_index[image_id] = os.path.join(root, file)\n",
    "        return image_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DDVZ7jIhg28X",
   "metadata": {
    "id": "DDVZ7jIhg28X"
   },
   "outputs": [],
   "source": [
    "image_dir = \"\"\n",
    "mask_dir = \"\"\n",
    "\n",
    "# Load full dataset and split by year\n",
    "full_dataset = FilamentDataset(image_dir=image_dir, mask_dir=mask_dir, transform=None)\n",
    "train_years = {2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018}\n",
    "val_years = {2019, 2020}\n",
    "test_years = {2021, 2022}\n",
    "train_idx, val_idx, test_idx = split_dataset_by_year(full_dataset, train_years, val_years, test_years)\n",
    "\n",
    "# Toggle for quick prototyping\n",
    "use_small_subset = False  # Set to False for full dataset\n",
    "\n",
    "if use_small_subset:\n",
    "    RANDOM_SEED = 42\n",
    "    random.seed(RANDOM_SEED)\n",
    "    train_idx = random.sample(train_idx, min(200, len(train_idx)))\n",
    "    val_idx = random.sample(val_idx, min(50, len(val_idx)))\n",
    "    test_idx = random.sample(test_idx, min(50, len(test_idx)))\n",
    "\n",
    "# Shared Transform\n",
    "shared_transform = ImageMaskTransform(image_size=(512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EWpVKOASNUQa",
   "metadata": {
    "id": "EWpVKOASNUQa"
   },
   "outputs": [],
   "source": [
    "# Subset Data\n",
    "train_dataset = Subset(FilamentDataset(image_dir, mask_dir, transform=shared_transform), train_idx)\n",
    "val_dataset = Subset(FilamentDataset(image_dir, mask_dir, transform=shared_transform), val_idx)\n",
    "test_dataset = Subset(FilamentDataset(image_dir, mask_dir, transform=shared_transform), test_idx)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UvNHAB-CM6Ge",
   "metadata": {
    "id": "UvNHAB-CM6Ge"
   },
   "source": [
    "U-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cm_IQwEBYeA8",
   "metadata": {
    "id": "Cm_IQwEBYeA8"
   },
   "outputs": [],
   "source": [
    "# Basic Double Convolution (Conv -> ReLU -> Conv -> ReLU)\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Vanilla U-Net\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Downsampling path\n",
    "        ch = in_channels\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(ch, feature))\n",
    "            ch = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Upsampling path\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        # Final output conv\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Decoder\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            x = self.ups[i](x)  # up-conv\n",
    "            skip = skip_connections[i // 2]\n",
    "\n",
    "            # Resize if needed (for odd input sizes)\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:])\n",
    "\n",
    "            # Concatenate skip connection\n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self.ups[i + 1](x)  # double conv\n",
    "\n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "glOxejOF1F_J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "glOxejOF1F_J",
    "outputId": "a7f90b87-9848-4f2c-8a00-5f049595f86f"
   },
   "outputs": [],
   "source": [
    "# Soft IoU\n",
    "def soft_iou(pred, target, smooth=1.0):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
    "    union = (pred + target - pred * target).sum(dim=(1, 2, 3))\n",
    "    return ((intersection + smooth) / (union + smooth)).mean().item()\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if len(train_loader) == 0 or len(val_loader) == 0:\n",
    "    raise ValueError(\"Train or validation loader is empty.\")\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_ious, val_ious = [], []\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_iou = 0.0, 0.0\n",
    "    for img, mask, _ in train_loader:\n",
    "        img, mask = img.to(device), mask.to(device)\n",
    "        pred = model(img)\n",
    "        loss = loss_fn(pred, mask)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_iou += soft_iou(pred, mask)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_iou = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for img, mask, _ in val_loader:\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            pred = model(img)\n",
    "            val_loss += loss_fn(pred, mask).item()\n",
    "            val_iou += soft_iou(pred, mask)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_train_iou = train_iou / len(train_loader)\n",
    "    avg_val_iou = val_iou / len(val_loader)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    train_ious.append(avg_train_iou)\n",
    "    val_ious.append(avg_val_iou)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, IoU: {avg_train_iou:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, IoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            random_idx = np.random.randint(0, len(val_dataset))\n",
    "            image, mask, _ = val_dataset[random_idx]\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "            mask = mask.unsqueeze(0).to(device)\n",
    "            pred = model(image)\n",
    "            pred_bin = (torch.sigmoid(pred[0]) > 0.5).float().cpu().numpy()[0]\n",
    "            mask_vis = mask[0].cpu().numpy()[0]\n",
    "            img_vis = image[0].cpu().numpy()[0]\n",
    "\n",
    "            plt.figure(figsize=(12, 3))\n",
    "            plt.subplot(1, 3, 1); plt.imshow(img_vis, cmap='gray'); plt.title('Input Image')\n",
    "            plt.subplot(1, 3, 2); plt.imshow(mask_vis, cmap='gray'); plt.title('Ground Truth')\n",
    "            plt.subplot(1, 3, 3); plt.imshow(pred_bin, cmap='gray'); plt.title('Prediction (Binary)')\n",
    "            plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8tgBTYj8ZbHh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "8tgBTYj8ZbHh",
    "outputId": "f00a62dc-e6f9-4937-8367-fdff8da03131"
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set_context(\"paper\", font_scale=1.4)\n",
    "sns.set_style(\"white\")  \n",
    "colors = sns.color_palette(\"Dark2\", 4)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=150)\n",
    "\n",
    "axes[0].plot(train_losses, label='Train Loss', marker='D', markersize=6,\n",
    "             color=colors[0], linewidth=2)\n",
    "axes[0].plot(val_losses, label='Val Loss', marker='o', markersize=6,\n",
    "             color=colors[1], linewidth=2)\n",
    "axes[0].set_title('Loss vs Epoch', fontsize=14, weight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend(frameon=False)\n",
    "\n",
    "axes[1].plot(train_ious, label='Train IoU', marker='D', markersize=6,\n",
    "             color=colors[2], linewidth=2)\n",
    "axes[1].plot(val_ious, label='Val IoU', marker='o', markersize=6,\n",
    "             color=colors[3], linewidth=2)\n",
    "axes[1].set_title('IoU vs Epoch', fontsize=14, weight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('IoU')\n",
    "axes[1].legend(frameon=False)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_facecolor('white')  \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EUm53S38wolG",
   "metadata": {
    "id": "EUm53S38wolG"
   },
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ivuq1QU_k5VI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivuq1QU_k5VI",
    "outputId": "ed73eeaa-53f9-49d6-cd25-a7f3583abdc9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import label as connected_components\n",
    "import time\n",
    "\n",
    "# 1. Pairwise IoU per image\n",
    "def compute_pairwise_iou(gt_mask, pred_mask):\n",
    "    \"\"\"\n",
    "    Compute pairwise IoU between objects in gt_mask and pred_mask (both binary 2D arrays).\n",
    "    Returns a list of IoU values for all matched object pairs.\n",
    "    \"\"\"\n",
    "    labeled_gt, n_gt = connected_components(gt_mask)\n",
    "    labeled_pred, n_pred = connected_components(pred_mask)\n",
    "\n",
    "    ious = []\n",
    "    for i in range(1, n_gt + 1):\n",
    "        gt_component = (labeled_gt == i)\n",
    "        if gt_component.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        overlap_pred_labels = np.unique(labeled_pred[gt_component])\n",
    "        overlap_pred_labels = overlap_pred_labels[overlap_pred_labels != 0]\n",
    "\n",
    "        for j in overlap_pred_labels:\n",
    "            pred_component = (labeled_pred == j)\n",
    "            intersection = np.logical_and(gt_component, pred_component).sum()\n",
    "            union = np.logical_or(gt_component, pred_component).sum()\n",
    "            if union > 0:\n",
    "                iou = intersection / union\n",
    "                ious.append(iou)\n",
    "\n",
    "    return ious if ious else [0.0]\n",
    "\n",
    "# Mean pairwise IoU per image\n",
    "def compute_mean_pairwise_iou_per_image(gt_mask, pred_mask):\n",
    "    ious = compute_pairwise_iou(gt_mask, pred_mask)\n",
    "    return np.mean(ious)\n",
    "\n",
    "# Dataset-level mean pairwise IoU (over all images and objects)\n",
    "def compute_dataset_pairwise_miou(gt_masks, pred_masks):\n",
    "    start_time = time.time()\n",
    "    all_ious = []\n",
    "    for i in range(gt_masks.shape[0]):\n",
    "        ious = compute_pairwise_iou(gt_masks[i, 0] > 0.5, pred_masks[i, 0] > 0.5)\n",
    "        all_ious.extend(ious)\n",
    "    result = float(np.mean(all_ious)) if all_ious else 0.0\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Dataset Pairwise mIoU computation took: {duration:.2f}s\")\n",
    "    return result\n",
    "\n",
    "# 2. Multiscale IoU per image\n",
    "def downsample_mask(mask, scale):\n",
    "    \"\"\"\n",
    "    Downsamples mask tensor of shape [B,C,H,W] by given scale using bilinear interpolation.\n",
    "    \"\"\"\n",
    "    B, C, H, W = mask.shape\n",
    "    new_H, new_W = max(1, int(H * scale)), max(1, int(W * scale))\n",
    "    return F.interpolate(mask, size=(new_H, new_W), mode='bilinear', align_corners=False)\n",
    "\n",
    "def multiscale_ratio(gt, pred, scales):\n",
    "    \"\"\"\n",
    "    Computes average IoU ratio over multiple scales for one sample (gt, pred tensors).\n",
    "    gt, pred shape: [1, 1, H, W]\n",
    "    \"\"\"\n",
    "    total = 0.0\n",
    "    for scale in scales:\n",
    "        gt_s = downsample_mask(gt, scale) > 0.5\n",
    "        pred_s = downsample_mask(pred, scale) > 0.5\n",
    "\n",
    "        # Convert to boolean numpy arrays for sum\n",
    "        gt_s_np = gt_s.cpu().numpy().astype(bool).squeeze()\n",
    "        pred_s_np = pred_s.cpu().numpy().astype(bool).squeeze()\n",
    "\n",
    "        intersection = np.logical_and(gt_s_np, pred_s_np).sum()\n",
    "        gt_pixels = gt_s_np.sum()\n",
    "        total += (intersection / gt_pixels) if gt_pixels > 0 else 1.0\n",
    "    return total / len(scales)\n",
    "\n",
    "def compute_multiscale_iou_per_sample(gt_masks, pred_masks, scales=np.logspace(-2, 0, 10)):\n",
    "    start_time = time.time()\n",
    "    iou_per_sample = []\n",
    "    for i in range(gt_masks.shape[0]):\n",
    "        gt_tensor = torch.tensor(gt_masks[i:i+1]).float()\n",
    "        pred_tensor = torch.tensor(pred_masks[i:i+1]).float()\n",
    "        iou = multiscale_ratio(gt_tensor, pred_tensor, scales)\n",
    "        iou_per_sample.append(iou)\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Multiscale IoU computation took: {duration:.2f}s\")\n",
    "    return iou_per_sample\n",
    "\n",
    "def compute_mean_multiscale_iou(gt_masks, pred_masks, scales=np.logspace(-2, 0, 10)):\n",
    "    iou_per_sample = compute_multiscale_iou_per_sample(gt_masks, pred_masks, scales)\n",
    "    return np.mean(iou_per_sample)\n",
    "\n",
    "# 3. Collect predictions and labels from model + dataloader\n",
    "def collect_predictions_and_labels(model, dataloader, device):\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    all_probs, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, masks, _ in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            targets = masks.cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    preds_05 = (all_probs > 0.5).astype(np.uint8)\n",
    "\n",
    "    y_true_flat = all_targets.flatten()\n",
    "    y_score_flat = all_probs.flatten()\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Prediction collection took: {duration:.2f}s\")\n",
    "\n",
    "    return y_true_flat, y_score_flat, preds_05, all_targets\n",
    "\n",
    "# 4. Evaluation pipeline to combine metrics\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"→ Collecting predictions...\")\n",
    "    y_true, y_score, preds_05, y_targets = collect_predictions_and_labels(model, test_loader, device)\n",
    "\n",
    "    print(\"→ Computing Pairwise mIoU@0.5...\")\n",
    "    pairwise_miou_05 = compute_dataset_pairwise_miou(y_targets, preds_05)\n",
    "\n",
    "    print(\"→ Computing Multiscale IoU...\")\n",
    "    miou_multiscale = compute_mean_multiscale_iou(y_targets, preds_05)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_duration = end_time - start_time\n",
    "    print(f\"\\n=== Total Evaluation Time: {total_duration:.2f} seconds ===\")\n",
    "\n",
    "    print(\"\\n=== Evaluation Results ===\")\n",
    "    print(f\"Pairwise mIoU@0.5: {pairwise_miou_05:.4f}\")\n",
    "    print(f\"Multiscale IoU (MIoU): {miou_multiscale:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"Pairwise_mIoU@0.5\": pairwise_miou_05,\n",
    "        \"MIoU_multiscale\": miou_multiscale\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ZDrL7xqGPi",
   "metadata": {
    "id": "73ZDrL7xqGPi"
   },
   "outputs": [],
   "source": [
    "results = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet() \n",
    "model.load_state_dict(torch.load(\"\"))\n",
    "model = model.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MChXiD0to_He",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "MChXiD0to_He",
    "outputId": "7a7b6d0a-227e-4657-d127-a83a427823e4"
   },
   "outputs": [],
   "source": [
    "def visualize_prediction(model, dataset, device, index=0):\n",
    "    model.eval()\n",
    "\n",
    "    image, gt_mask, _ = dataset[index]  \n",
    "    image_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(image_tensor)\n",
    "        pred_mask = torch.sigmoid(pred).squeeze().cpu().numpy()\n",
    "\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "    gt_mask = gt_mask.squeeze().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # Convert image tensor to numpy array\n",
    "    img_np = image.squeeze().cpu().numpy()\n",
    "    if img_np.ndim == 3:\n",
    "        img_np_show = np.moveaxis(img_np, 0, -1)\n",
    "    else:\n",
    "        img_np_show = img_np\n",
    "\n",
    "    H_img, W_img = img_np_show.shape[:2]\n",
    "\n",
    "    # Resize masks if needed\n",
    "    if gt_mask.shape != (H_img, W_img):\n",
    "        gt_mask = resize(gt_mask, (H_img, W_img), order=0, preserve_range=True).astype(np.uint8)\n",
    "    if pred_mask.shape != (H_img, W_img):\n",
    "        pred_mask = resize(pred_mask, (H_img, W_img), order=0, preserve_range=True).astype(np.uint8)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    for ax in axs:\n",
    "        if img_np_show.ndim == 2:\n",
    "            ax.imshow(img_np_show, cmap='gray')\n",
    "        else:\n",
    "            ax.imshow(img_np_show)\n",
    "        ax.axis('off')\n",
    "\n",
    "    axs[0].set_title(\"Input Image\")\n",
    "\n",
    "    # GT overlay (green)\n",
    "    gt_overlay = np.zeros((H_img, W_img, 4), dtype=np.float32)\n",
    "    gt_overlay[gt_mask == 1] = [0, 0.5, 0, 0.6]\n",
    "    axs[1].imshow(gt_overlay)\n",
    "    axs[1].set_title(\"Image + Ground Truth Mask\")\n",
    "\n",
    "    # Pred overlay (red)\n",
    "    pred_overlay = np.zeros((H_img, W_img, 4), dtype=np.float32)\n",
    "    pred_overlay[pred_mask == 1] = [0.5, 0, 0.5, 1]\n",
    "    axs[2].imshow(pred_overlay)\n",
    "    axs[2].set_title(\"Image + Predicted Mask\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y3kChvPcqBYJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "y3kChvPcqBYJ",
    "outputId": "0a98dc77-4e01-44df-f2b1-7f1a0efce949"
   },
   "outputs": [],
   "source": [
    "visualize_prediction(model, train_dataset, device, index=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbZ2P7bD6S99",
   "metadata": {
    "id": "cbZ2P7bD6S99"
   },
   "source": [
    "Generating IoUs boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wDUXDbjX6XIT",
   "metadata": {
    "id": "wDUXDbjX6XIT"
   },
   "outputs": [],
   "source": [
    "def generate_all_boxplots_in_row(model, dataloader, device, max_images=30, save_name=\"boxplots.pdf\"):\n",
    "    model.eval()\n",
    "    spacing = 0.7\n",
    "    fig_width = max_images * spacing\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 7), dpi=600)\n",
    "\n",
    "    image_counter = 0\n",
    "    boxplot_positions = []\n",
    "    xtick_labels = []\n",
    "    scales = np.logspace(-2, 0, 10)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks, filenames in tqdm(dataloader, desc=\"Generating Boxplots\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(float)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                if image_counter >= max_images:\n",
    "                    break\n",
    "\n",
    "                gt_mask = masks[i, 0].cpu().numpy() > 0.5\n",
    "                pred_mask = preds[i, 0]\n",
    "                pred_prob = probs[i, 0]\n",
    "                pairwise_ious = compute_pairwise_iou(gt_mask, pred_mask)\n",
    "                if isinstance(pairwise_ious, (int, float)):\n",
    "                    pairwise_ious = [pairwise_ious]\n",
    "                if len(pairwise_ious) <= 1:\n",
    "                    continue\n",
    "\n",
    "                multiscale_iou = multiscale_ratio(\n",
    "                    torch.tensor(gt_mask).unsqueeze(0).unsqueeze(0).float(),\n",
    "                    torch.tensor(pred_mask).unsqueeze(0).unsqueeze(0).float(),\n",
    "                    scales\n",
    "                )\n",
    "                mean_iou = np.mean(pairwise_ious)\n",
    "                median_iou = np.median(pairwise_ious)\n",
    "                if median_iou <= 0:\n",
    "                    continue\n",
    "\n",
    "                pos = (image_counter + 1) * spacing\n",
    "                boxplot_positions.append(pos)\n",
    "                xtick_labels.append(str(filenames[i]))\n",
    "\n",
    "                ax.boxplot(\n",
    "                    pairwise_ious,\n",
    "                    positions=[pos],\n",
    "                    patch_artist=True,\n",
    "                    showfliers=True,\n",
    "                    widths=0.35,\n",
    "                    boxprops=dict(facecolor='#393432', edgecolor='#000000', linewidth=0.5),\n",
    "                    medianprops=dict(color='#00bfff', linewidth=4),\n",
    "                    flierprops=dict(marker='o', markerfacecolor='none', markeredgecolor='black', markersize=10),\n",
    "                    whiskerprops=dict(color='#000000', linewidth=0.6),\n",
    "                    capprops=dict(color='#000000', linewidth=1.8),\n",
    "                )\n",
    "\n",
    "                ax.plot(pos, multiscale_iou, marker='^', color='red', markersize=10, linestyle='None')  \n",
    "                ax.plot(pos, mean_iou, marker='s', markerfacecolor='none', markeredgecolor='yellow', markersize=10, linestyle='None')  \n",
    "\n",
    "                image_counter += 1\n",
    "            if image_counter >= max_images:\n",
    "                break\n",
    "\n",
    "    bottom_margin, top_margin = 0.02, 0.03\n",
    "    left_margin = spacing * 0.5\n",
    "    right_margin = spacing * 0.5\n",
    "    pos_max = boxplot_positions[-1] if boxplot_positions else max_images * spacing\n",
    "\n",
    "    ax.set_xlim(left_margin, pos_max + right_margin)\n",
    "    ax.set_ylim(-bottom_margin, 1 + top_margin)\n",
    "\n",
    "    ax.set_yticks(np.linspace(0, 1, 6))\n",
    "    ax.set_xticks(boxplot_positions)\n",
    "    ax.tick_params(axis='x', which='both', labelbottom=False)\n",
    "\n",
    "    ax.set_ylabel('IoU', fontsize=25, fontfamily='DejaVu Sans', color='black') \n",
    "\n",
    "\n",
    "    ax.tick_params(axis='both', which='both', direction='out',\n",
    "                   length=6, width=1.5, labelsize=15, color='black')\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks() + ax.yaxis.get_major_ticks():\n",
    "        tick.tick1line.set_clip_on(False)\n",
    "        tick.tick2line.set_clip_on(False)\n",
    "\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    rect = patches.Rectangle(\n",
    "        (left_margin, -bottom_margin),\n",
    "        pos_max + right_margin - left_margin,\n",
    "        1 + top_margin + bottom_margin,\n",
    "        linewidth=1.5, edgecolor='black', facecolor='none',\n",
    "        zorder=10, clip_on=False\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='^', linestyle='None', color='red', label='Multiscale IoU', markersize=10),  \n",
    "        Line2D([0], [0], marker='s', linestyle='None', markerfacecolor='none', markeredgecolor='yellow', label='Mean Pairwise IoU', markersize=10),  \n",
    "        Line2D([0], [0], marker='o', linestyle='None', color='none', markerfacecolor='none', markeredgecolor='black', label='Outliers', markersize=10),  \n",
    "        Line2D([0], [0], linestyle='-', color='#00bfff', linewidth=3, label='Median (boxplot)'), \n",
    "        Line2D([0], [0], color='black', linewidth=3, label='Pairwise IoU Distribution')  \n",
    "    ]\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(os.getcwd(), save_name)\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nFilenames corresponding to boxplots:\")\n",
    "    for name in xtick_labels:\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd840b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_all_boxplots_in_row(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    max_images=30,\n",
    "    save_name=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ed170",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='^', linestyle='None', color='red', label=r'$IoU_{\\mathit{multiscale}}$', markersize=12),\n",
    "    Line2D([0], [0], marker='s', linestyle='None', markerfacecolor='none', markeredgecolor='yellow',\n",
    "           label=r'$mIoU_{\\mathit{pairwise}}$', markersize=12),\n",
    "    Line2D([0], [0], marker='o', linestyle='None', color='none', markerfacecolor='none', markeredgecolor='black',\n",
    "           label=r'$IoU_{\\mathit{pairwise}}\\ \\text{Outliers}$', markersize=12),\n",
    "    Line2D([0], [0], linestyle='-', color='#00bfff', linewidth=3,\n",
    "           label=r'$IoU_{\\mathit{pairwise}}\\ \\text{Median}$')\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2), dpi=600)\n",
    "ax.axis('off')\n",
    "\n",
    "legend = ax.legend(\n",
    "    handles=legend_elements,\n",
    "    loc='center',\n",
    "    frameon=True,\n",
    "    facecolor='#d3d3d3',\n",
    "    edgecolor='none',\n",
    "    framealpha=1,\n",
    "    ncol=len(legend_elements),\n",
    "    handlelength=1.2,\n",
    "    handletextpad=0.2,\n",
    "    columnspacing=1.8,\n",
    "    fontsize=25,\n",
    "    borderpad=0.8\n",
    ")\n",
    "\n",
    "legend.get_frame().set_boxstyle(\"square\")\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "bbox = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "\n",
    "plt.savefig(\"\", bbox_inches=bbox, dpi=600, transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed66a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction_on_raw_image(model, image_path, device, input_size=(512, 512)):\n",
    "    model.eval()\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    original_size = img.size\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    image_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(image_tensor)\n",
    "        if isinstance(pred, dict):\n",
    "            pred = pred['logits'] if 'logits' in pred else list(pred.values())[0]\n",
    "        pred = interpolate(pred, size=input_size, mode=\"bilinear\", align_corners=False)\n",
    "        pred_mask = torch.sigmoid(pred).squeeze().cpu().numpy()\n",
    "\n",
    "    pred_mask_bin = (pred_mask > 0.5).astype(np.uint8)\n",
    "    pred_mask_resized = np.array(Image.fromarray(pred_mask_bin * 255).resize(original_size, Image.NEAREST)) // 255\n",
    "\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    img_vis = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
    "\n",
    "    img_rgb = np.stack([img_vis]*3, axis=-1)\n",
    "\n",
    "    pred_overlay = img_rgb.copy()\n",
    "    pred_overlay[pred_mask_resized == 1] = [1, 0, 0]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    axs[0].imshow(img_rgb, cmap=\"gray\")\n",
    "    axs[0].set_title(\"Original H-alpha Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(pred_overlay)\n",
    "    axs[1].set_title(\"Model Prediction Overlay (Blue)\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"\"\n",
    "visualize_prediction_on_raw_image(model=model, image_path=image_path, device=\"cuda\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0cca9474-4111-4610-ae71-784b4e580e5d",
    "6a7863a6-5b7d-4aae-97c4-60086bf5d22a",
    "cb7dea38-8b19-4d95-84ef-416ba0dfdafc",
    "ba8417e9-a301-43f0-a0df-f29eff3fb53c"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
